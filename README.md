## Optimization methods

# Course description

Лекция 1-2. Краткий обзор численных методов оптимизации. Итеративная схема методов оптимизации. Сложность и классы задач оптимизации. Выпуклые и сильно выпуклые задачи.

Лекция 2-3. Невыпуклые, гладкие и негладкие задачи. Основы матрично-векторного дифференцирования. Условия оптимальности первого и второго порядка, субдифференциал и его свойства. Методы одномерной минимизации (методы Фибоначчи, золотого сечения, дихотомии). Методы маломерной оптимизации (методы центров тяжести и эллипсоидов). 

Лекция 4. Метод градиентного спуска, наискорейший спуск, способы выбора шага (+ адаптивный метод). Правила Армихо, Голдстейна, Нестерова. Сопряженные направления. Метод сопряженных градиентов для минимизации квадратичных функций. Метод сопряженных градиентов для решения задачи выпуклой оптимизации. Ускоренный градиентный метод в вариациях метода подобных треугольников и моментов Нестерова).

Лекция 5. Метод Ньютона + вариация с кубической регуляризацией. Квазиньютоновские методы (BFGS, LBFGS).

Лекция 6. Задачи с регуляризацией. Проксимальный градиентный спуск, проксимальный стохастический спуск.

Лекция 7. Методы редукции дисперсии (SAGA, SVRG, Loopless-SVRG как частный случай SGD). Мини-батчинг. Условия сильного (SGC) и слабого (WGC) роста. 

Лекция 8. Невыпуклая оптимизация. Адаптивные стохастические методы (Adagrad, Adadelta, RMSProp, Momentum SGD и прочие).

Лекция 9. Задачи оптимизации на множествах простой структуры. Дивергенция Брэгмана. Метод проекции градиента, метод зеркального спуска. Метод Франк-Вульфа об условном градиенте. 

Лекция 10. Краткое описание понятия NP-сложности. NP-сложность задач невыпуклой несладкой оптимизации. Нижние оценки сложности методов первого порядка для минимизации сумм. Методы для минимизации сумм (Katyusha, MiG, SSNM (гладкие выпуклый и сильно выпуклый случай). 

Лекция 11. Оптимальные методы для общей задачи стохастический оптимизации (стох. метод Нестерова с мини-батчингом. Стохастический зеркальный спуск.

Лекция 12. Распределенная оптимизация. Централизованная и децентрализованная оптимизация на примере SGD. Квантизация. Спарсификация. Федеративное обучение. 

Лучшая литература по методам оптимизации

 ⁃ Поляк Б.Т. Введение в оптимизацию
 ⁃ Beck A. FIRST-ORDER METHODS IN OPTIMIZATION
 ⁃ Нестеров Ю.Е. Методы выпуклой оптимизации 
 ⁃ Nocedal J., Wright S. Numerical optimization
 ⁃ Сухарев А.Г., Тимохов А.В., Федоров В.В. Курс методов оптимизации
 ⁃ Измайлов А.Ф., Солодов М.В. Численные методы оптимизации

Домашние задания 

Всего — 6 домашних заданий (два — на математику, четыре — на алгоритмы и программирование). 
Каждое задание содержит в себе задачи разного уровня сложности. На математические ДЗ будет даваться по неделе, на программистские — по две. Решение усложненных задач необязательно, но гарантированно даст возможность получит автоматом «отлично» вместо экзамена. Для допуска к экзамену необходимо решить 50% от каждого ДЗ (из числа обычных задач). 